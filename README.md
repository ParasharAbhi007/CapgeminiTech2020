# CapgeminiTech2020
# Challenge 1
## Document Analysis Solution using Amazon Textract, Amazon Comprehend and Amazon A2I
As business grow, there is a commensurate growth in the number of documents that need to be analyzed. Traditionally, businesses had to manually review documents as they came in, but now, this process can be automated with help of Machine Learning and Artificial Intelligence technologies in Amazon Web Services.

# Introduction
This solution uses Amazon Textract, Amazon Comprehend and Amazon A2I to deploy an end-to-end document analysis solution. This solution takes documents in the for of scanned images as input performs the following steps on them:

## Amazon Textract to extract the text from the uploaded images
Recreate the document (in text format) using an AWS Lambda Function
Use Amazon Comprehend to analyse the text and perform Custom Named Entity Recognition on the extracted text
Use Amazon Augmented AI (Amazon A2I) to send the extract entities and the text to a human reviewer for a human review for any missing entities
Collate the results and feedback provided by the human reviewer and retrain the model every time new custom entities are detected.
Solution Architecture


## Setup Resources
In order to setup the required resources for this solution, you need to execute the Cloudformation Template that is provided with the solution. Once you have completed the prerequisites listed below, you should be able to deploy the Cloudformation Template in your account.

### Prerequisites
There are 2 prerequisite steps that you need to perform before you can deploy this solution to your AWS account and here are the steps to do them:

Create a Human Review Workflow
Create an S3 Bucket called S3BucketNamePlaceholder in the region that you intend to deploy this solution.

Your bucket name should be different than the one above and unique in the region but this tutorial will use S3BucketNamePlaceholder when it references to this bucket.

Create a private workforce from the Amazon Sagemaker console.

Create a Custom Worker Template from Amazon Augmented AI console. Use the file /code/ui/translate_template.html as the custom template.

Create a Flow Definition from the Amazon Augmented AI console.

## Use S3BucketNamePlaceholder for S3 Bucket.
For IAM role, choose 'Create a new role'.
For Task Type, choose 'Custom'
For Template, choose the custom worker template you created in step 4 above.
For Worker Types, choose 'Private'.
For Private Teams, choose the team you created in step 3 above.
After creation, copy the Flow Definition ARN. We will use it later.
Train the Comprehend Custom Entity Model
#### Go to S3 console, and create a folder called comprehend-data in S3BucketNamePlaceholder Bucket.

Copy the contents of the folder ./comprehend-cer-resources/ in the comprehend-data folder.

Go to Amazon Comprehend and train a custom entity recognizer using the files you just copied in comprehend-data folder.

## Parameters
There are several parameters that you would need to deploy the Cloudformation template to your account. This section lists those parameters so that you understand them and get prepared for deploying the Cloudformation Template.

S3BucketName
Use the same bucket that you have used so far and enter S3BucketNamePlaceholder in this box.

### CustomEntityTrainingDatasetS3URI
The dataset that will be used for training the Amazon Comprehend Custom Entity Recognizer. For this example, a single file contains all the training data, one document per line. An example document is available in `./comprehend-cer-resources/raw_text.csv'

CustomEntityTrainingListS3URI
This document contains the list of Custom Entities as shown here. An example file can be found in `./comprehend-cer-resources/entity_list.csv'

### CustomEntityRecognizerArn
Train a Custom Entity Recognizer using the documents above as shown here. Once you have trained the Custom Entity Recognizer, you can use the ARN as a parameter to the Cloudformation template.

### FlowDefinitionARN
Use the task template available at ./ui/task-template.html to create a Custom Human Review workflow as shown here. Once the workflow becomes available to use, the ARN of this workflow can be used as FlowDefinitionARN parameter.

### S3ComprehendBucketName
Provide any random string to be a bucket name (which needs to be unique in the region). This string will be used as the bucket name for storing the data generated by Amazon Comprehend temporarily. You don't need to create this bucket. The Cloudformation template will create it and manage it for you.

### Package and Deploy the Cloudformation Template
Create an S3 Bucket for storing packaged Cloudformation Resources
Create an S3 Bucket by the name CFN-RESOURCES-123456789 (replace CFN-RESOURCES-123456789 with your own bucket name) to host your Cloudformation resources.

### Package the Cloudformation Template
Package the Cloudformation Template and code for the Lambdas using the following command:

aws cloudformation package --template-file ./source/Textract-Comprehend-A2I.yaml --output-template-file ./source/CFN-Output-Textract-Comprehend-A2I.yaml --s3-bucket CFN-RESOURCES-123456789 --region us-east-1 --force-upload

### Deploy the Cloudformation Template
Now that you have packaged your code you can run the following command to deploy the Cloudformation Template.

## aws cloudformation deploy --template-file ./source/CFN-Output-Textract-Comprehend-A2I.yaml --region us-east-1 --capabilities CAPABILITY_IAM --stack-name <INSERT STACK NAME HERE> --parameter-overrides S3BucketName=<INSERT PARAMETER HERE> FlowDefinitionARN=<INSERT PARAMETER HERE> CustomEntityRecognizerARN=<INSERT PARAMETER HERE> S3ComprehendBucketName=<INSERT PARAMETER HERE> CustomEntityTrainingListS3URI=<INSERT PARAMETER HERE> CustomEntityTrainingDatasetS3URI=<INSERT PARAMETER HERE>

## Test the Deployment
Go to the S3 Bucket, S3BucketNamePlaceholder, and create a new folder titled input. Whenever you will upload a .jpeg, or a .png file in this folder, the workflow will begin.

Log in to your A2I Review Console and make an desired changes.

## Results
At the end of each day, a Cloudwatch Event invokes a Lambda function automatically that looks for any new custom entities that the human reviewers may have identified using the Amazon A2I worker portal. If there are any identities that did not exist in the entity list file that was used to train the model, then it retrains the Amazon Comprehend Custom Entity model and uses the new model for inference thereafter.

This automated retraining process, allows the model to improve perpetually and requires lesser human intervention over time, hence saving time and cost for your business.



# Challenge2
## Solution Overview
We will build a Mobile or Web application that allows users to sign in using an email and require the user to upload a document containing his or her photo. We will use the AWS Amplify Framework to integrate our Front-End application with Amazon S3 and store this image in a secure and encrypted bucket.  Our solution will trigger a Lambda function for each new image uploaded to this bucket so that we can index the images inside Amazon Rekognition and save the metadata in a DynamoDB table for later queries.

For authentication, this solution uses Amazon Cognito User Pools combined with Lambda functions to customize the authentication flows together with the Amazon Rekognition CompareFaces API to identify the confidence level between user photos provided during Sign Up and Sign In.

### Here’s a step-wise description of the above data-flow architecture diagram:

1.User signs up into the Cognito User Pool.

2.User uploads – during Sign Up – a document image containing his/her photo and name, to an S3 Bucket (e.g. Passport).

3.A Lambda function is triggered containing the uploaded image as payload.

4.The function first indexes the image in a specific Amazon Rekognition Collection to store these user documents.

5.The same function then persists in a DynamoDB table as the indexed image metadata, together with the email registered in Amazon Cognito User Pool for later queries.

6.User enters an email in the custom Sign In page, which makes a request to Cognito User Pool.

7.Amazon Cognito User Pool triggers the “Define Auth Challenge” trigger that determines which custom challenges are to be created at this moment.

8.The User Pool then invokes the “Create Auth Challenge” trigger. This trigger queries the DynamoDB table for the user containing the given email id to retrieve its indexed photo from the Amazon Rekognition Collection.

9.The User Pool invokes the “Verify Auth Challenge” trigger. This verifies if the challenge was indeed successfully completed; if it finds an image, it will compare it with the photo taken during Sign In to measure its confidence between both the images.

10.The User Pool, once again, invokes the “Define Auth Challenge” trigger that verifies if the challenge was answered. No no further challenges are created, if the ‘Define Auth challenge’ is able to verify the user-supplied answer. The trigger response, back to the User Poll will include an “issueTokens:true” attribute to authenticate itself and finally issue the user a JSON Web Token (JWT)

## The following solution is available as a Serverless application. 

Users are required to use a valid email as user name.

The solution includes a Cognito App Client configured to “Only allow custom authentication” as Amazon Cognito requires a password for user sign up. We are creating a random password to these users, since we don’t want them to Sign In using these passwords later.

We use two Amazon S3 Buckets: one to store document images uploaded during Sign Up and one to store user photos taken when Signing In for face comparisons.

We use two different Lambda runtimes (Python and Node.js) to demonstrate how AWS Serverless Application Model (SAM) handles multiple runtimes in the same project and development environment for the developer’s perspective.
### The following Lambda functions are triggered to implement the images indexing in Amazon Rekognition and customize Amazon Cognito User Pools custom authentication challenges:

Create Rekognition Collection (Python 3.6) – This Lambda function gets triggered only once, at the beginning of deployment, to create a Custom Collection in Amazon Rekognition to index documents for user Sign Ups.

Index Images (Python 3.6) – This Lambda function gets triggered for each new document upload to Amazon S3 during Sign Up and indexes the uploaded document in the Amazon Rekognition Collection (mentioned in the previous step) and then persists its metadata into DynamoDB.

Define Auth Challenge (Node.js 8.10) – This Lambda function tracks the custom authentication flow, which is comparable to a decider function in a state machine. It determines which challenges are presented, in what order, to the user. At the end, it reports back to the user pool if the user succeeded or failed authentication. The Lambda function is invoked at the start of the custom authentication flow and also after each completion of the “Verify Auth Challenge Response” trigger.

Create Auth Challenge (Node.js 8.10) – This Lambda function gets invoked, based on the instruction of the “Define Auth Challenge” trigger, to create a unique challenge for the user. We will use this function to query DynamoDB for existing user records and if their given metadata are valid.

Verify Auth Challenge Response (Node.js 8.10) – This Lambda function gets invoked by the user pool when the user provides the answer to the challenge. Its only job is to determine if that answer is correct. In this case, it compares both images provided during Sign Up and Sign In, using the Amazon Rekognition CompareFaces API and considers a API responses containing a confidence level equals or greater than 90% as a valid challenge response.
